{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/paulotguerra/QXD0178/blob/main/01.E0-Exercicio-Classificacao-de-dados.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QXD0178 - Mineração de Dados\n",
    "# Preparação da base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Professor:** Paulo de Tarso Guerra Oliveira ([paulodetarso@ufc.br](mailto:paulodetarso@ufc.br))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lista de Exercícios: Classificação de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta lista de exercícios, você explorará a aplicação de métodos de aprendizado de máquina para realizar tarefas de classificação de dados. Você usará a base de dados [Food choices: College students' food and cooking preferences](https://www.kaggle.com/datasets/borapajo/food-choices?select=food_coded.csv) e avaliará vários algoritmos de classificação para determinar sua eficácia. O objetivo é entender como diferentes métodos de aprendizado de máquina se comportam em relação à acurácia na classificação de dados.\n",
    "\n",
    "O exercício será dividido em várias etapas:\n",
    "\n",
    "1. **Pré-processamento dos dados:**\n",
    "   - Descreva brevemente o conjunto de dados   \n",
    "   - Limpe o conjunto de dados, tratando valores ausentes, removendo duplicatas e realizando transformações necessárias. \n",
    "   - Caso você use os dados pré-processados na lista anterior, faça um breve descritivo dos principais ajustes.\n",
    "   - Codifique variáveis categóricas, se necessário, para que possam ser utilizadas em algoritmos de aprendizado de máquina.\n",
    "   - Cria a coluna `self_perception_overweight` com valor: `True` se a coluna `self_perception_weight` tem valor 4 ou 5; e `False`, caso contrário.\n",
    "   - Remova a coluna `self_perception_weight` do conjunto de dados.\n",
    "2. **Divisão do conjunto de dados:**\n",
    "   - Divida o conjunto de dados em um conjunto de treinamento e um conjunto de teste para avaliar o desempenho dos algoritmos. \n",
    "   - O mesmo conjunto de teste deve ser usado por todos os algoritmos analizados e nenhum dado deste pode ser usado na fase de treinamento.\n",
    "   - O atributo alvo (*rótulo*) da classificação será o campo `self_perception_overweight`.   \n",
    "3. **Seleção de algoritmos de classificação:**\n",
    "   - Selecione uma variedade de algoritmos de aprendizado de máquina para testar na tarefa de classificação.   \n",
    "   - Sua seleção deve conter, no mínimo, os seguintes métodos: Naive Bayes, k-Nearest Neighbors, Support Vector Machine (Linear/RBF), Decision Trees, Random Forest, Multilayer Perceptron.\n",
    "   - Descreva brevemente como funciona cada algoritmo selecionado.\n",
    "4. **Treinamento e avaliação:**\n",
    "   - Treine os algoritmos de classificação usando todo o conjunto de treinamento. \n",
    "   - Avalie o desempenho de cada algoritmo no conjunto de teste usando métricas como acurácia, precisão, recall e F1-score.\n",
    "   - Repita a análise treinando os algoritmos com validação cruzada.\n",
    "   - Repita a análise realizando ajuste de hiperparâmetros.\n",
    "5. **Análise dos resultados:**\n",
    "   - Prepare um texto que descreva os resultados obtidos e faça uma análise crítica destes resultados.\n",
    "   - Compare o desempenho dos diferentes algoritmos e explique por que alguns apresentaram resultados mais adequados que outros.\n",
    "   \n",
    "Documente todas as etapas em um arquivo Jupyter Notebook (`.ipynb`) que inclua as análises, o código e as justificativas. Lembre-se de que é fundamental justificar todas as decisões tomadas ao longo do processo e documentar as análises de forma clara e concisa. Este trabalho tem como objetivo proporcionar uma compreensão prática da seleção e avaliação de algoritmos de classificação em cenários de aprendizado supervisionado.\n",
    "\n",
    "Envie seu Jupyter Notebook até a data de entrega especificada nesta tarefa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solução\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descrição da base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A base de dados consiste em um conjunto de dados que coleta informações sobre as escolhas alimentares e preferências culinárias de estudantes universitários. A base de dados inclui informações desde dados demográficos como sexo e renda, passando por dados relacionados a preferências alimentares como comida favorita, estimativa de quantas calorias possui determinado elemento e etc. As colunas presentes na base de dados são: 'GPA', 'Gender', 'breakfast', 'calories_chicken', 'calories_day','calories_scone', 'coffee', 'comfort_food', 'comfort_food_reasons', 'comfort_food_reasons_coded', 'cook', 'comfort_food_reasons_coded.1', 'cuisine', 'diet_current', 'diet_current_coded', 'drink', 'eating_changes', 'eating_changes_coded', 'eating_changes_coded1', 'eating_out', 'employment', 'ethnic_food', 'exercise', 'father_education', 'father_profession', 'fav_cuisine', 'fav_cuisine_coded', 'fav_food', 'food_childhood', 'fries', 'fruit_day', 'grade_level', 'greek_food', 'healthy_feeling', 'healthy_meal', 'ideal_diet', 'ideal_diet_coded', 'income', 'indian_food', 'italian_food', 'life_rewarding', 'marital_status', 'meals_dinner_friend', 'mother_education', 'mother_profession', 'nutritional_check', 'on_off_campus', 'parents_cook', 'pay_meal_out', 'persian_food', 'self_perception_weight', 'soup', 'sports', 'thai_food', 'tortilla_calories', 'turkey_calories', 'type_sports', 'veggies_day', 'vitamins', 'waffle_calories', 'weight'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza da base de dados\n",
    "Foi realizado a substituição de valores NaN e alguns que não faziam sentido no contexto da coluna localizada na base de dados para valores que fizessem sentido e não gerasse resultados muito tendenciosos. No caso de valores númericos, foram utilizadas estratégias como, por exemplo, a substituição por valores de média e moda. Em valores de string, foram substituídos NaN por uma única constante 'none', considerada como valor vazio. Além disso, para outras strings que não faziam sentido dentro de seu contexto como 'personal' onde esperava-se um resultado, usar outra unidade de peso etc. foi implementado mais uma vez o valor none. Por último, também houve a exclusão de linhas inteiras cujo a maioria dos valores ou até todos eles eram NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/She-Codes-Now/Intro-to-Data-Science-with-R/master/food_coded.csv\")\n",
    "df\n",
    "df['soup'].fillna(df['soup'].mode()[0], inplace=True)\n",
    "df['sports'].fillna(df['sports'].mode()[0], inplace=True)\n",
    "media = df['calories_day'].mean()\n",
    "media_rounded = round(media,1)\n",
    "df['calories_day'].fillna(media_rounded, inplace=True)\n",
    "df['tortilla_calories'].fillna(df['tortilla_calories'].mode()[0], inplace=True)\n",
    "df['calories_scone'].fillna(df['calories_scone'].mode()[0], inplace=True)\n",
    "del df['comfort_food_reasons_coded']\n",
    "df.rename(columns={'comfort_food_reasons_coded.1': 'comfort_food_reasons_coded'}, inplace=True)\n",
    "media = df['cook'].mean()\n",
    "media_rounded = round(media,0)\n",
    "df['cook'].fillna(media_rounded, inplace=True)\n",
    "df['cuisine'].fillna(df['cuisine'].mode()[0], inplace=True)\n",
    "media = df['drink'].mean()\n",
    "media_rounded = round(media,0)\n",
    "df['drink'].fillna(media_rounded, inplace=True)\n",
    "media = df['employment'].mean()\n",
    "media_rounded = round(media,0)\n",
    "df['employment'].fillna(media_rounded, inplace=True)\n",
    "media = df['exercise'].mean()\n",
    "media_rounded = round(media,0)\n",
    "df['exercise'].fillna(media_rounded, inplace=True)\n",
    "media = df['father_education'].mean()\n",
    "media_rounded = round(media,0)\n",
    "df['father_education'].fillna(media_rounded, inplace=True)\n",
    "df['fav_food'].fillna(df['fav_food'].mode()[0], inplace=True)\n",
    "media = df['income'].mean()\n",
    "media_rounded = round(media,0)\n",
    "df['income'].fillna(media_rounded, inplace=True)\n",
    "media = df['life_rewarding'].mean()\n",
    "media_rounded = round(media,0)\n",
    "df['life_rewarding'].fillna(media_rounded, inplace=True)\n",
    "mode = df['marital_status'].mode()[0]\n",
    "df['marital_status'].fillna(mode, inplace=True)\n",
    "df.at[74, 'marital_status'] = mode\n",
    "media = df['mother_education'].mean()\n",
    "media_rounded = round(media,0)\n",
    "df['mother_education'].fillna(media_rounded, inplace=True)\n",
    "df['on_off_campus'].fillna(df['on_off_campus'].mode()[0], inplace=True)\n",
    "media = df['persian_food'].mean()\n",
    "media_rounded = round(media,0)\n",
    "df['persian_food'].fillna(media_rounded, inplace=True)\n",
    "media = df['self_perception_weight'].mean()\n",
    "media_rounded = round(media,0)\n",
    "df['self_perception_weight'].fillna(media_rounded, inplace=True)\n",
    "df.at[2, 'weight'] = np.nan\n",
    "df['weight'] = df['weight'].str.extract('(\\d+)').astype(float)\n",
    "media = df['weight'].mean()\n",
    "media_rounded = round(media,0)\n",
    "df.at[2, 'weight'] = media_rounded\n",
    "df['weight'].fillna(media_rounded, inplace=True)\n",
    "df.at[61, 'GPA'] = np.nan\n",
    "df.at[104, 'GPA'] = np.nan\n",
    "df['GPA'] = df['GPA'].str.extract('(\\d+)').astype(float)\n",
    "media = df['GPA'].mean()\n",
    "df['GPA'].fillna(media, inplace=True)\n",
    "df = df.drop(74).reset_index(drop=True)\n",
    "df['eating_changes'].fillna('none', inplace=True)\n",
    "df['father_profession'].fillna('none', inplace=True)\n",
    "df['meals_dinner_friend'].fillna('none', inplace=True)\n",
    "df['mother_profession'].fillna('none', inplace=True)\n",
    "df['type_sports'].fillna('none', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colocando todas as strings em minúsculas\n",
    "df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "# Tirando os espaços em branco\n",
    "df = df.applymap(lambda x: x.replace(\" \", \"\") if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando uma tabela que representa se o estudante pratica ou não esportes. Isso ajudará o algoritmo pois há a tendência natural que praticar esportes tende à dificultar a existência de sobrepeso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "119    1\n",
       "120    1\n",
       "121    0\n",
       "122    0\n",
       "123    0\n",
       "Name: practice_sports, Length: 124, dtype: int32"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['practice_sports'] = np.where(df['type_sports'] != 'none', 1, 0)\n",
    "df['practice_sports']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando categorias númericas para os tipos de culinária favoritos dos estudantes. Imagino que possa haver uma tendência de determinada culinária ocasionar uma sensação de sobrepeso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       6\n",
       "1      23\n",
       "2      23\n",
       "3      45\n",
       "4      23\n",
       "       ..\n",
       "119    23\n",
       "120    36\n",
       "121    30\n",
       "122    23\n",
       "123    17\n",
       "Name: fav_cuisine_cat, Length: 124, dtype: int32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['fav_cuisine_cat'] = le.fit_transform(df['fav_cuisine'])\n",
    "df['fav_cuisine_cat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pegando as comidas que mais aparecem na tabela `comfort_food`, a quantidade 10 foi só um valor que achei considerável considerando o tamanho da base de dados. Então, eu crio uma nova coluna númerica que verifica se aquele estudante tem como `comfort_food` pelo menos 1 dessas comidas. Faço isso pois, se for confirmado que estudantes que tem determinada comida como `comfort_food` tiverem uma tendência a se encontrarem acima do peso, isso pode ser um bom parâmetro para o algoritmo trabalhar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "119    1\n",
       "120    0\n",
       "121    0\n",
       "122    1\n",
       "123    1\n",
       "Name: got_popular_comfort_food, Length: 124, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "foods = ','.join(df['comfort_food']).split(',')\n",
    "couting_foods = Counter(foods)\n",
    "foods_more_than_10 = [food for food, counting in couting_foods.items() if counting >= 10]\n",
    "foods_more_than_10\n",
    "\n",
    "def find_food(s):\n",
    "    foods = s.split(',')\n",
    "    for food in foods:\n",
    "        if food in foods_more_than_10:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "df['got_popular_comfort_food'] = df['comfort_food'].apply(find_food)\n",
    "df['got_popular_comfort_food']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fiz um processo semelhante, porém para `food_chilhood` pois, a infância costuma ser uma idade propensa a desenvolver tendências de saúde, uma vez que não há todo o conhecimento e a dedicação a desenvolver bons hábitos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "119    0\n",
       "120    0\n",
       "121    0\n",
       "122    0\n",
       "123    0\n",
       "Name: got_popular_food_childhood, Length: 124, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "foods = ','.join(df['food_childhood']).split(',')\n",
    "couting_foods = Counter(foods)\n",
    "foods_more_than_10 = [food for food, counting in couting_foods.items() if counting >= 10]\n",
    "foods_more_than_10\n",
    "\n",
    "def find_food(s):\n",
    "    foods = s.split(',')\n",
    "    for food in foods:\n",
    "        if food in foods_more_than_10:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "df['got_popular_food_childhood'] = df['food_childhood'].apply(find_food)\n",
    "df['got_popular_food_childhood']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remocao de dados abertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('comfort_food', axis=1, inplace=True)\n",
    "df.drop('comfort_food_reasons', axis=1, inplace=True)\n",
    "df.drop('diet_current', axis=1, inplace=True)\n",
    "df.drop('eating_changes', axis=1, inplace=True)\n",
    "df.drop('father_profession', axis=1, inplace=True)\n",
    "df.drop('fav_cuisine', axis=1, inplace=True)\n",
    "df.drop('food_childhood', axis=1, inplace=True)\n",
    "df.drop('healthy_meal', axis=1, inplace=True)\n",
    "df.drop('ideal_diet', axis=1, inplace=True)\n",
    "df.drop('meals_dinner_friend', axis=1, inplace=True)\n",
    "df.drop('mother_profession', axis=1, inplace=True)\n",
    "df.drop('type_sports', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando a coluna self_perception_overweight removendo a self_perception_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['self_perception_overweight'] = (df['self_perception_weight'] == 4.0) | (df['self_perception_weight'] == 5.0)\n",
    "df.drop('self_perception_weight', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão do conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df['self_perception_overweight']\n",
    "X = df.drop(columns=['self_perception_overweight'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção de algoritmos de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção e descrição dos algoritmos selecionados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes\n",
    "Algoritmo probabilístico que se baseia no teorema de Bayes para realizar tarefas de classificação. Ele assume que as caracteristicas de um determinado dado são independentes umas das outras. É rotineiramente usado para classificar dados de diversos tipos, como numéricos, categóricos e mistos.\n",
    "####  K-Nearest Neighbors\n",
    "Algoritmo que classifica uma nova observação com base nas observações mais próximas dela no espaço de atributos. Esse número de observações sendo especificado pelo hiperparâmetro K.\n",
    "#### Support Vector Machine\n",
    "Algoritmo que consiste em encontrar um hiperplano de separação ótimo entre duas classes em um espaço de atributos. É amplamente utilizado em tarefas de classificação binária, onde o objetivo é separar as observações em duas classes distintas.\n",
    "#### Decision Tree\n",
    "Algoritmo que classifica dados criando uma árvore de decisão. A árvore é construída dividindo o conjunto de dados em subconjuntos cada vez menores, com base nos valores das características. \n",
    "#### Random Forest\n",
    "Algoritmo que combina várias árvores de decisão. Isso ajuda o modelo a generalizar melhor para dados novos, reduzindo o risco de sobreajuste\n",
    "####  Multilayer Perceptron\n",
    "Algoritmo que usa uma rede neural artificial para classificar dados. Essa rede neural é composta por várias camadas de neurônios, que são conectados uns aos outros por pesos. A rede neural aprende a classificar dados ajustando os pesos dos neurônios.\n",
    "#### Regressão Logística\n",
    "Algoritmo que classifica dados usando uma função logística. Tal função é uma função matemática que mapeia um intervalo de números reais para o intervalo ente 0 e 1.Para classificar uma nova observação, o algoritmo de regressão logística calcula a probabilidade de a observação pertencer a cada classe. A observação é então classificada na classe com a probabilidade mais alta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento e avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.48\n",
      "Precisão: 0.35294117647058826\n",
      "Recall: 0.75\n",
      "F1-Score: 0.48\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Precisão:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.62\n",
      "Precisão: 0.3333333333333333\n",
      "Recall: 0.1875\n",
      "F1-Score: 0.24000000000000005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5) \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Precisão:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.66\n",
      "Precisão: 0.4666666666666667\n",
      "Recall: 0.4375\n",
      "F1-Score: 0.45161290322580644\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model = SVC(kernel='linear', C=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Precisão:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.68\n",
      "Precisão: 0.5\n",
      "Recall: 0.4375\n",
      "F1-Score: 0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model = DecisionTreeClassifier(criterion='gini', max_depth=None)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Precisão:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.7\n",
      "Precisão: 0.6666666666666666\n",
      "Recall: 0.125\n",
      "F1-Score: 0.21052631578947367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=None)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Precisão:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.56\n",
      "Precisão: 0.125\n",
      "Recall: 0.0625\n",
      "F1-Score: 0.08333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Precisão:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.68\n",
      "Precisão: 0.5\n",
      "Recall: 0.25\n",
      "F1-Score: 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\as390\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model = LogisticRegression(C=1.0, penalty='l2')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Precisão:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Validação Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.5080645161290323\n",
      "Precisão: 0.32857142857142857\n",
      "Recall: 0.6216216216216216\n",
      "F1-Score: 0.42990654205607476\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model = MultinomialNB()\n",
    "y_pred = cross_val_predict(model, X, y, cv=5)  \n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Precisão:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.6209677419354839\n",
      "Precisão: 0.1875\n",
      "Recall: 0.08108108108108109\n",
      "F1-Score: 0.11320754716981132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)  \n",
    "\n",
    "y_pred = cross_val_predict(model, X, y, cv=5)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Precisão:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.6290322580645161\n",
      "Precisão: 0.38461538461538464\n",
      "Recall: 0.40540540540540543\n",
      "F1-Score: 0.39473684210526316\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model = SVC(kernel='linear', C=1.0)\n",
    "\n",
    "y_pred = cross_val_predict(model, X, y, cv=5)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Precisão:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.6451612903225806\n",
      "Precisão: 0.41025641025641024\n",
      "Recall: 0.43243243243243246\n",
      "F1-Score: 0.42105263157894735\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model = DecisionTreeClassifier(criterion='gini', max_depth=None) \n",
    "\n",
    "y_pred = cross_val_predict(model, X, y, cv=5)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Precisão:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.7096774193548387\n",
      "Precisão: 0.6\n",
      "Recall: 0.08108108108108109\n",
      "F1-Score: 0.14285714285714288\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None)\n",
    "\n",
    "y_pred = cross_val_predict(model, X, y, cv=5)  \n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Precisão:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.6612903225806451\n",
      "Precisão: 0.35294117647058826\n",
      "Recall: 0.16216216216216217\n",
      "F1-Score: 0.22222222222222227\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', max_iter=1000)  \n",
    "\n",
    "y_pred = cross_val_predict(model, X, y, cv=5)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Precisão:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\as390\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\as390\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\as390\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\as390\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.6451612903225806\n",
      "Precisão: 0.4\n",
      "Recall: 0.3783783783783784\n",
      "F1-Score: 0.3888888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\as390\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, solver='lbfgs')\n",
    "\n",
    "y_pred = cross_val_predict(model, X, y, cv=5)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Precisão:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modificando os hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.48\n",
      "Precisão: 0.35294117647058826\n",
      "Recall: 0.75\n",
      "F1-Score: 0.48\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Precisão:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.66\n",
      "Precisão: 0.42857142857142855\n",
      "Recall: 0.1875\n",
      "F1-Score: 0.26086956521739124\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=15) \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Precisão:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.66\n",
      "Precisão: 0.4666666666666667\n",
      "Recall: 0.4375\n",
      "F1-Score: 0.45161290322580644\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ajuste de hiperparametro C\n",
    "model = SVC(kernel='linear', C=10.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Precisão:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.6\n",
      "Precisão: 0.375\n",
      "Recall: 0.375\n",
      "F1-Score: 0.375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Precisão:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.7\n",
      "Precisão: 1.0\n",
      "Recall: 0.0625\n",
      "F1-Score: 0.11764705882352941\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth=None)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Precisão:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.46\n",
      "Precisão: 0.21052631578947367\n",
      "Recall: 0.25\n",
      "F1-Score: 0.22857142857142856\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(150, 75), activation='relu', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Precisão:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.68\n",
      "Precisão: 0.5\n",
      "Recall: 0.25\n",
      "F1-Score: 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\as390\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model = LogisticRegression(C=0.1, penalty='l2')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Precisão:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise dos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao executar as métricas de desempenho, obetivemos os seguintes resultados:\n",
    "#### Naive Bayes:\n",
    "Acurácia: 0.48\n",
    "Precisão: 0.35294117647058826\n",
    "Recall: 0.75\n",
    "F1-Score: 0.48\n",
    "Como podemos ver, o Naive Bayes obteve uma alta taxa de recall, o que significa que ele se saiu bem em identificar positivos corretos, porém a acurácia e a precisão tiveram um desempenho relativamente baixo em comparação aos outros. Isso pode indicar que o modelo tem dificuldade em equilibrar falsos positivos e verdadeiros positivos.\n",
    "#### K-Nearest Neighbors:\n",
    "Acurácia: 0.62\n",
    "Precisão: 0.3333333333333333\n",
    "Recall: 0.1875\n",
    "F1-Score: 0.24000000000000005\n",
    "O KNN teve teve um desempenho geral moderado. Ele obteve uma acurácia que rivaliza com alguns dos mais bem colocados da lista, poém ou outros indicadores tiveram resultados relativamente baixos. O que indica que, embora o algoritmo tenha acertado uma boa parte das instâncias, ele ainda não lida muito bem com os falsos positivos e verdadeiros positivos.\n",
    "#### Support Vector Machine:\n",
    "Acurácia: 0.66\n",
    "Precisão: 0.4666666666666667\n",
    "Recall: 0.4375\n",
    "F1-Score: 0.45161290322580644\n",
    "O SVM teve um desempenho moderado, com uma acurácia de 0.66 e uma precisão de, aproximadamente, 0.5. Apesar a precisão ter sido razoável, o recall mais baixo indica que o modelo pode ter dificuldade em recuperar todos os positivos verdadeiros.\n",
    "#### Decision Tree:\n",
    "Acurácia: 0.68\n",
    "Precisão: 0.5\n",
    "Recall: 0.4375\n",
    "F1-Score: 0.4666666666666667\n",
    "A decisionn tree obteve uma acurácia considerada intermediária para alta em comparação com outros modelos. A precisão e o recall, no entanto, são relativamente baixos, o que sugere que o modelo pode ter problemas de equilíbrio entre falsos positivos e verdadeiros positivos.\n",
    "#### Random Forest:\n",
    "Acurácia: 0.72\n",
    "Precisão: 1.0\n",
    "Recall: 0.125\n",
    "F1-Score: 0.2222222222222222\n",
    "O Random Forest obteve a maior acurácia entre os modelos, mas sua precisão é muito alta e o recall é muito baixo. Isso indica que o modelo pode estar superajustado aos dados de treinamento, resultando em baixo recall e alta precisão.\n",
    "#### Multilayer Perceptron:\n",
    "Acurácia: 0.6612903225806451\n",
    "Precisão: 0.35294117647058826\n",
    "Recall: 0.16216216216216217\n",
    "F1-Score: 0.22222222222222227\n",
    "O Muktilayer Perceptron obteve uma acurácia intermediária. Tanto a precisão quanto o recall são baixos, o que sugere que o modelo pode estar tendo dificuldades em equilibrar o compromisso entre falsos positivos e verdadeiros positivos. De uma maneira geral, ele foi um algoritmo que teve baixo desepenho entre os analisados.\n",
    "#### Regressão Lógica:\n",
    "Acurácia: 0.68\n",
    "Precisão: 0.5\n",
    "Recall: 0.25\n",
    "F1-Score: 0.3333333333333333\n",
    "A regressão logística obteve uma acurácia razoável. A precisão está em um nível intermediário, enquantoa a recall está baixa.Com isso, podemos ver que o modelo não consegue determinar muito fielmente verdadeiros positivos, embora tenha conseguido classificar corretamente um bom número de instâncias.\n",
    "\n",
    "Ao compararmos a complexidade do Random Forest e do MLP, podemos ter uma boa noção do desempenho dos 2. Percebemos que os conjuntos de dados tinha uma boa quantidade de valores a se trabalhar para chegar à conclusão esperada. Sendo assim, a lógica do Random Forest pode ter trabalhado de maneira mais concisa ou até mais adequada frente à base de dados, enquanto a lógica do MLP pode ter se perdido na manipulação dos dados e garantido os valores baixos em recall e precisão.Relativo ao KNN, percebemos uma acurácia moderada para baixa enquanto todos os outros indicadores tiveram um desepenho relativamente baixo, o que pode ser justificado pela grande quantidade de características existentes na base de dados, resultando em uma distribuição desequilibrada das classes para o algoritmo usa para trabalhar. A acurácia baixa do Naive Bayes pode ter se dado à simplicidade exarcebada do algoritmo. Isso, aliado à distribuição majoritariamente númerica do formato de dados (o que geralmente vai contra a natureza do algoritmo, que é mais utilizado para dados categóricos) pode indicar o porquê ele não conseguiu trabalhar muito bem os dados para chegar no resultado esperado. Já a regressão lógica, desempenhou de forma intermediária na acurácia e precisão, provavelmente devido à simplicidade adota pelo funcionamento do algoritmo. No entando, ao analisarmos a taxa de recall e f1-score baixa, podemos supor que a falta de consistência entre as classes foi o principal fator para o algoritmo ter performado de forma baixa. No caso da Decision Tree, seu desempenho relativamente baixo pode ter sido dado ao fato dos conjuntos de dados terem muitos valores e não terem uma ligação direta entre si para chegar ao resultado esperado. De uma maneira geral, podemos ver que os diferente algoritmos de classificação são mais adequados em diferentes contextos. É necessário fazer uma análise e um estudo cuidadoso para saber qual é mais adequado frente à sua base de dados e o objetivo que você quer chegar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
